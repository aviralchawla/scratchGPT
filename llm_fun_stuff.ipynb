{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107b9de90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from scratchGPT.utils import Tokenizer, Dataset\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data as full text ------>\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "Data as tokenized integers ------>\n",
      "[43, 49, 16, 55, 56, 34, 21, 49, 56, 49, 19, 47, 27, 10, 61, 41, 47, 11, 52, 16, 47, 34, 64, 47, 34, 50, 16, 52, 0, 47, 47, 1, 34, 14, 27, 33, 34, 11, 53, 16, 56, 63, 47, 16, 48, 34, 63, 47, 14, 16, 34, 12, 47, 34, 55, 50, 47, 14, 30, 6, 61, 61, 32, 13, 13, 10, 61, 57, 50, 47, 14, 30, 48, 34, 55, 50, 47, 14, 30, 6, 61, 61, 43, 49, 16, 55, 56, 34, 21, 49, 56, 49, 19, 47, 27, 10, 61, 9, 52, 53]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(text)\n",
    "print('Data as full text ------>')\n",
    "print(text[:100])\n",
    "print('Data as tokenized integers ------>')\n",
    "print(tokenizer.encode(text[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model parameters\n",
    "n = 20 # context size\n",
    "v = len(tokenizer) # vocab size\n",
    "d = 64 # embedding dimension\n",
    "a = 4 # number of attention heads\n",
    "d_k = d // a\n",
    "d_v = d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor(tokenizer.encode(text[:n])) # tokenized text\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 64])\n"
     ]
    }
   ],
   "source": [
    "E = torch.normal(0, 0.02, (v, d)) # embedding matrix\n",
    "P = torch.normal(0, 0.02, (n, d)) # positional encoding\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x: torch.Tensor, gamma=0.5, beta=0.5):\n",
    "    return ((x - x.mean()) / x.std()) * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "X = E[T] + P[:n] # n x d\n",
    "print(X.shape) # n x d\n",
    "X = layer_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "# query, key, value\n",
    "W_Q = [torch.normal(0, 0.02, (d, d_k)) for _ in range(a)]\n",
    "W_K = [torch.normal(0, 0.02, (d, d_k)) for _ in range(a)]\n",
    "W_V = [torch.normal(0, 0.02, (d, d_v)) for _ in range(a)]\n",
    "\n",
    "print(W_Q[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [X @ W_Q[i] for i in range(a)]\n",
    "K = [X @ W_K[i] for i in range(a)]\n",
    "V = [X @ W_V[i] for i in range(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_querykey(Q, K):\n",
    "    o = Q @ K.T\n",
    "    masked = torch.tril(o)\n",
    "    masked = torch.masked_fill(masked, masked == 0, float('-inf'))\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "Ma = [masked_querykey(Q[i], K[i]) for i in range(a)]\n",
    "Ma = [m/np.sqrt(d_k) for m in Ma]\n",
    "print(Ma[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: torch.Tensor):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "SoftMa = [softmax(m) for m in Ma]\n",
    "H = torch.concat([SoftMa[i] @ V[i] for i in range(a)], dim=1)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "W_O = torch.normal(0, 0.02, (d, d))\n",
    "O = H @ W_O\n",
    "O = X + O\n",
    "print(O.shape)\n",
    "\n",
    "O = layer_norm(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward\n",
    "W_1 = torch.normal(0, 0.02, (d, d))\n",
    "W_2 = torch.normal(0, 0.02, (d, d))\n",
    "b_1 = torch.zeros(d)\n",
    "b_2 = torch.zeros(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: torch.Tensor):\n",
    "    return torch.max(x, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = relu(O @ W_1 + b_1) @ W_2 + b_2\n",
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = O + F\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembedd = output[-1] @ E.T\n",
    "unembedd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = softmax(unembedd)\n",
    "probabilities.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratchGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
